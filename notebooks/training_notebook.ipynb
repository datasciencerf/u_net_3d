{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIOTJA\\AppData\\Local\\Continuum\\anaconda3\\envs\\ptorch\\lib\\site-packages\\pkg_resources\\__init__.py:1151: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  self, resource_name\n",
      "C:\\Users\\DIOTJA\\AppData\\Local\\Continuum\\anaconda3\\envs\\ptorch\\lib\\site-packages\\pkg_resources\\__init__.py:1151: DeprecationWarning: Use of .. or absolute path in a resource path is not allowed and will raise exceptions in a future release.\n",
      "  self, resource_name\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "os.chdir(pathlib.Path(os.getcwd()).parent)\n",
    "from dnn.model_pipeline import UNetPipeline, get_masked_daily_product\n",
    "from dnn.model_pipeline import ndvi, get_cdl, isin, crops_list\n",
    "import descarteslabs as dl\n",
    "import numpy as np\n",
    "from descarteslabs.client.services import Places\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import shapely\n",
    "import shapely.ops\n",
    "import shapely.prepared\n",
    "import rasterio.features\n",
    "import ipyleaflet\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the Tilated Image Collection and Get Rid of Invalid Tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tiles: 62635\n"
     ]
    }
   ],
   "source": [
    "# Create the Central Valley AOI and Tilation\n",
    "sac = shapely.geometry.shape(\n",
    "    dl.places.shape(\"north-america_united-states_california_sacramento-valley\").geometry\n",
    ")\n",
    "sj = shapely.geometry.shape(\n",
    "    dl.places.shape(\"north-america_united-states_california_san-joaquin-valley\").geometry)\n",
    "central_valley_aoi = sac.union(sj)\n",
    "\n",
    "tiles = dl.scenes.DLTile.from_shape(\n",
    "    central_valley_aoi, resolution=20, tilesize=64, pad=0)\n",
    "print(f'Number of tiles: {len(tiles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Relevant Image Collections from our AOI / Tiles\n",
    "start_datetime = \"2017-01-01\"\n",
    "end_datetime = \"2020-01-01\"\n",
    "# Create Landsat Image Collection\n",
    "l8_daily = get_masked_daily_product(\n",
    "    \"landsat:LC08:01:T1:TOAR\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "l8_daily = l8_daily.concat_bands(ndvi(l8_daily))\n",
    "# Create CDL Image Collection\n",
    "cdl = get_cdl(start_date=\"2017-01-01\", end_date=\"2020-01-01\")\n",
    "is_crops = isin(cdl, crops_list)\n",
    "is_crops_19 = is_crops[-1]\n",
    "four_year_combo = is_crops.sum(axis=\"images\") + is_crops_19  # double-weight 2019\n",
    "four_year_binary = four_year_combo >= 2\n",
    "cdl_mask = ~four_year_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job ID: 04bf41fc256ff5c644774430ae5bb4ca9783ead0a5061001\n",
      "[######] | Steps: 10/10 | Stage: SUCCEEDED                                    \n",
      "Job ID: 04bf41fc256ff5c644774430ae5bb4ca9783ead0a5061001\n",
      "length of shapes: 4957\n",
      "Type of all_valid: <class 'shapely.geometry.multipolygon.MultiPolygon'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83df4ddaced545abb3e4fdd8e3a02090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62635.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No. Valid Tiles: 19914\n",
      "Percentage of valid tiles: 31.79372555280594\n"
     ]
    }
   ],
   "source": [
    "# Find the the valid tiles\n",
    "central_valley_ctx = dl.scenes.AOI(central_valley_aoi, shape=(2048, 2048), crs=\"EPSG:4326\")\n",
    "all_cdl = four_year_binary.compute(central_valley_ctx)\n",
    "all_cdl.geocontext[\"gdal_geotrans\"]\n",
    "shapes = list(\n",
    "    geom for geom, value in\n",
    "    rasterio.features.shapes(\n",
    "        all_cdl.ndarray.astype(\"uint8\"), \n",
    "        transform=rasterio.transform.Affine.from_gdal(*all_cdl.geocontext[\"gdal_geotrans\"])\n",
    "    )\n",
    "    if value == 1\n",
    ")\n",
    "print(f\"length of shapes: {len(shapes)}\")\n",
    "all_valid = shapely.ops.unary_union([shapely.geometry.shape(s) for s in shapes]).simplify(0.3)\n",
    "print(f'Type of all_valid: {type(all_valid)}')\n",
    "all_valid_prepped = shapely.prepared.prep(all_valid)\n",
    "valid_tiles = [t for t in tqdm(tiles) if all_valid_prepped.intersects(t.geometry)]\n",
    "print(f'No. Valid Tiles: {len(valid_tiles)}')\n",
    "print(f'Percentage of valid tiles: {100*(len(valid_tiles) / len(tiles))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the U-Net Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Unet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_input (InputLayer)        [(None, 12, 64, 64,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 12, 64, 64, 6 24          image_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 12, 64, 64, 1 2608        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 12, 64, 64, 1 64          conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 12, 64, 64, 1 6928        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 64, 64, 1 64          conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 12, 64, 64, 1 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 12, 64, 64, 1 64          dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 12, 64, 64, 3 13856       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 12, 64, 64, 3 128         conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 12, 64, 64, 3 27680       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 12, 64, 64, 3 128         conv3d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 12, 64, 64, 3 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 12, 64, 64, 3 128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d (MaxPooling3D)    (None, 6, 32, 32, 32 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 6, 32, 32, 64 55360       max_pooling3d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 32, 32, 64 256         conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 6, 32, 32, 64 110656      batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 32, 32, 64 256         conv3d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 6, 32, 32, 64 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 32, 32, 64 256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 6, 32, 32, 12 221312      batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 32, 32, 12 512         conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 6, 32, 32, 12 442496      batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 32, 32, 12 512         conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 32, 32, 12 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 32, 32, 12 512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3D)  (None, 3, 16, 16, 12 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 3, 16, 16, 12 0           max_pooling3d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 3, 16, 16, 12 512         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 3, 16, 16, 25 884992      batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 3, 16, 16, 25 1024        conv3d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 3, 16, 16, 25 1769728     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 3, 16, 16, 25 1024        conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 3, 16, 16, 25 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose (Conv3DTranspo (None, 6, 32, 32, 12 884864      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 6, 32, 32, 25 0           conv3d_transpose[0][0]           \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 6, 32, 32, 12 884864      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 6, 32, 32, 12 512         conv3d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 6, 32, 32, 12 442496      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 6, 32, 32, 12 512         conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 6, 32, 32, 12 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTrans (None, 12, 64, 64, 6 221248      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 12, 64, 64, 9 0           conv3d_transpose_1[0][0]         \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 12, 64, 64, 6 165952      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 12, 64, 64, 6 256         conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 12, 64, 64, 6 110656      batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 12, 64, 64, 6 256         conv3d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 12, 64, 64, 6 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 1, 64, 64, 49 37681       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1, 64, 64, 49 196         conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 4096, 49)     0           batch_normalization_20[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 6,290,573\n",
      "Trainable params: 6,286,975\n",
      "Non-trainable params: 3,598\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class_weight = [1] + [5] * 48\n",
    "unet_params = {\n",
    "    'img_height': 64,\n",
    "    'img_width': 64,\n",
    "    'bands': 6,\n",
    "    'time_steps': 12,\n",
    "    'nclasses': len(crops_list) + 1,\n",
    "    'class_weights': class_weight,\n",
    "    'learning_rate': 1e-3\n",
    "}\n",
    "random_seed = 2020\n",
    "L = len(valid_tiles)\n",
    "test_split = np.random.RandomState(random_seed)\n",
    "tr_ix = test_split.choice(np.arange(L), int(0.85 * L), replace=False)\n",
    "tst_ix = np.array([k for k in np.arange(L) if k not in tr_ix])\n",
    "u_net = UNetPipeline(model_params=unet_params, \n",
    "                     tiles=np.asanyarray(valid_tiles),\n",
    "                     img_prod_id=\"landsat:LC08:01:T1:TOAR\",\n",
    "                     train_ix=tr_ix,\n",
    "                     test_ix=tst_ix,\n",
    "                     random_seed=random_seed\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training ...\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 1 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 70.1059 - accuracy: 0.1210\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 16 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 70.3802 - accuracy: 0.1238\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 31 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 991us/step - loss: 79.0712 - accuracy: 0.2124\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 46 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 109.8340 - accuracy: 0.1322\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 61 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.7340 - accuracy: 0.2839\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 76 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 75.9949 - accuracy: 0.1731\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 91 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 110.5699 - accuracy: 0.0800\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 106 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 69.4595 - accuracy: 0.2154\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 121 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.7770 - accuracy: 0.1393\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 136 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 67.3141 - accuracy: 0.2695\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 151 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.8728 - accuracy: 0.2077\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 166 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 65.5200 - accuracy: 0.1681\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 181 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 981us/step - loss: 65.7962 - accuracy: 0.2327\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 196 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.6005 - accuracy: 0.0816\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 211 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 67.8991 - accuracy: 0.1647\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 226 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.4778 - accuracy: 0.1647\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 241 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.1423 - accuracy: 0.1979\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 256 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 981us/step - loss: 67.1884 - accuracy: 0.2232\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 271 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 71.2928 - accuracy: 0.1683\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 286 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.2255 - accuracy: 0.2090\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 301 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 66.8823 - accuracy: 0.0792\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 316 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.0440 - accuracy: 0.2125\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 331 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.6747 - accuracy: 0.1269\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 346 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.0753 - accuracy: 0.1278\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 361 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.9701 - accuracy: 0.1771\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 376 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.2955 - accuracy: 0.1079\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 391 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 66.1601 - accuracy: 0.2477\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 406 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.8549 - accuracy: 0.2146\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 421 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.7400 - accuracy: 0.2215\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 436 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 65.7404 - accuracy: 0.1244\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 451 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 995us/step - loss: 71.1232 - accuracy: 0.1161\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 466 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 66.2528 - accuracy: 0.1192\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 481 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 386us/step - loss: 65.7828 - accuracy: 0.1013\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 496 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.4588 - accuracy: 0.1654\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 511 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.6306 - accuracy: 0.2254\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 526 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.9786 - accuracy: 0.1203\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 541 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.3927 - accuracy: 0.2447\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 556 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.2760 - accuracy: 0.0753\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 571 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.1832 - accuracy: 0.1631\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 586 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.8447 - accuracy: 0.1950\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 601 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 67.2372 - accuracy: 0.1774\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 616 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 67.0034 - accuracy: 0.2447\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 631 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.3915 - accuracy: 0.1180\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 646 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.7488 - accuracy: 0.2603\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 661 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.7408 - accuracy: 0.1202\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 676 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 992us/step - loss: 65.3110 - accuracy: 0.1727\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 691 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.0368 - accuracy: 0.2234\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 706 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.1198 - accuracy: 0.0888\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 721 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 790us/step - loss: 66.7463 - accuracy: 0.1592\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 736 out of 1058\n",
      "################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 66.3230 - accuracy: 0.2791\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 751 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.3833 - accuracy: 0.2245\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 766 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.2167 - accuracy: 0.1293\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 781 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.6008 - accuracy: 0.2336\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 796 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.8125 - accuracy: 0.1259\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 811 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.8058 - accuracy: 0.1729\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 826 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.3089 - accuracy: 0.1844\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 841 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 976us/step - loss: 64.2231 - accuracy: 0.1906\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 856 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 65.1158 - accuracy: 0.1775\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 871 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 984us/step - loss: 67.1850 - accuracy: 0.2101\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 886 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 67.5468 - accuracy: 0.1390\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 901 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.3329 - accuracy: 0.2316\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 916 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 993us/step - loss: 65.7544 - accuracy: 0.2054\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 931 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 514us/step - loss: 66.1313 - accuracy: 0.1179\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 946 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 66.2145 - accuracy: 0.3084\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 961 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 65.1380 - accuracy: 0.2169\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 976 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 981us/step - loss: 69.2952 - accuracy: 0.1657\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 991 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 64.7417 - accuracy: 0.2126\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 1006 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 998us/step - loss: 66.3738 - accuracy: 0.2093\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 1021 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 102.1035 - accuracy: 0.1636\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 1036 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 64.3177 - accuracy: 0.1255\n",
      "Year 2017\n",
      "Epoch 1 / 2: \n",
      "Batch 1051 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 67.0272 - accuracy: 0.1284\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 1 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 65.0445 - accuracy: 0.1132\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 16 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 67.7004 - accuracy: 0.1113\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 31 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 983us/step - loss: 68.6546 - accuracy: 0.1692\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 46 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 0s/step - loss: 70.1679 - accuracy: 0.1205\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 61 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 70.0643 - accuracy: 0.0856\n",
      "Year 2018\n",
      "Epoch 1 / 2: \n",
      "Batch 76 out of 1058\n",
      "################################\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 68.8581 - accuracy: 0.1108\n"
     ]
    }
   ],
   "source": [
    "u_net.train_model(16, 2, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#u_net.save_model(str(pathlib.Path(os.getcwd()) / 'saved_models' / 'model3.h5'))\n",
    "#u_net.load_model(str(pathlib.Path(os.getcwd()) / 'saved_models' / 'model0.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load some test data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = u_net.data_loader(np.arange(5), '2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = u_net.model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#pd.Series(preds[0].argmax(1)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
