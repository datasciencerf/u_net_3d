{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "# ignore all future warnings / convergence warnings, !!! In a real workflow do not do this !!!\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=DeprecationWarning)\n",
    "import descarteslabs as dl\n",
    "import numpy as np\n",
    "import pickle\n",
    "from descarteslabs.client.services import Places\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import descarteslabs.workflows as wf\n",
    "import shapely.geometry\n",
    "import shapely.ops\n",
    "import shapely.prepared\n",
    "import rasterio.features\n",
    "from tqdm.notebook import tqdm\n",
    "import msgpack\n",
    "import msgpack_numpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_yday(tile_info):\n",
    "    date_t = tile_info['group']\n",
    "    return datetime.datetime.strptime(f\"{date_t[0]}-{date_t[1]}-{date_t[2]}\",\n",
    "                               \"%Y-%m-%d\").timetuple().tm_yday\n",
    "def get_yday_arrays(data, info):\n",
    "    # Assume single year of data\n",
    "    days = np.array([get_yday(t) - 1 for t in info])\n",
    "    yday_array = np.zeros((365, data.shape[1], data.shape[2], data.shape[3]))\n",
    "    yday_array[days] = data\n",
    "    return yday_array\n",
    "\n",
    "def get_monthly_arrays(data, info):\n",
    "    years = sorted(list(set([x['group'][0] for x in info])))\n",
    "    months = sorted(list(set([x['group'][1] for x in info])))\n",
    "    dates_ = list(zip(np.arange(data.shape[0], dtype=int), [x['group'] for x in info]))\n",
    "    date_ranges = {(x,y): [] for x in years for y in range(1,13)}\n",
    "    for d in dates_:\n",
    "        date_ranges[d[1][:2]].append(d[0])\n",
    "    avg_array = np.zeros((12*len(years), data.shape[1], data.shape[2], data.shape[3]))\n",
    "    for k, dr in enumerate(sorted([(x,y) for x in years for y in months])):\n",
    "        if date_ranges[dr]:\n",
    "            avg_array[k] = data[date_ranges[dr][0]:date_ranges[dr][-1]+1].mean(axis=0)\n",
    "    return avg_array\n",
    "\n",
    "def msgpack_to_numpy(byte_array):\n",
    "    return msgpack.unpackb(byte_array, object_hook=msgpack_numpy.decode)[0]\n",
    "\n",
    "def process_cdl(cdl_r, valid_crops):\n",
    "    flat = np.array(cdl_r).reshape(512*512)\n",
    "    flat = pd.Series(flat).apply(lambda v: v * (int(v) in valid_crops))\n",
    "    flat = flat.apply(lambda v: crops_enc[int(v)])\n",
    "    return flat.values.reshape((512,512))\n",
    "\n",
    "def get_dnn_data(img, crop, valid_crops):\n",
    "    crop = process_cdl(crop, valid_crops)\n",
    "    nz = np.where(crop > 0)\n",
    "    res_y = crop[nz]\n",
    "    res_x = img[:,:,nz[0],nz[1]].transpose((2,0,1))\n",
    "    return res_x, res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "'''sac = shapely.geometry.shape(\n",
    "    dl.places.shape(\"north-america_united-states_california_sacramento-valley\").geometry\n",
    ")\n",
    "sj = shapely.geometry.shape(\n",
    "    dl.places.shape(\n",
    "        \"north-america_united-states_california_san-joaquin-valley\"\n",
    "    ).geometry\n",
    ")\n",
    "central_valley_aoi = sac.union(sj)\n",
    "'''\n",
    "central_valley_aoi = dl.places.shape(\"north-america_united-states_california_san-joaquin-valley_stanislaus\")\n",
    "tiles = dl.scenes.DLTile.from_shape(\n",
    "    central_valley_aoi, resolution=15, tilesize=512, pad=0\n",
    ")\n",
    "print(len(tiles))\n",
    "start_datetime = \"2019-01-01\"\n",
    "end_datetime = \"2020-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud_masked_daily_product(product_id: str, start_datetime: str, end_datetime: str) -> wf.ImageCollection:\n",
    "    \"Get a product by ID, masked by the DL cloud mask and mosaicked by day\"\n",
    "    if 'airbus' in product_id.lower():\n",
    "        cloud = 'derived:visual_cloud_mask'\n",
    "    elif 'sentinel' in product_id.lower():\n",
    "        cloud = \"cloud-mask\"\n",
    "    else:\n",
    "        cloud = \"valid-cloudfree\"\n",
    "    ic = wf.ImageCollection.from_id(product_id, start_datetime, end_datetime)\n",
    "    cloudmask = (\n",
    "        wf.ImageCollection.from_id(\n",
    "            product_id, start_datetime, end_datetime\n",
    "        ).pick_bands(cloud)\n",
    "        == 0\n",
    "    )\n",
    "\n",
    "    # Make an ImageCollectionGroupby object, for quicker lookups from `ic` by date (you can use it like a dict)\n",
    "    ic_date_groupby = ic.groupby(dates=(\"year\", \"month\", \"day\"))\n",
    "    # For each cloudmask date, pick the corresponding image from `ic` by date, mosiac both, and mask them.\n",
    "    # (Not all scenes have cloudmasks processed, so this ensures we only return scenes that do.)\n",
    "    return cloudmask.groupby(dates=(\"year\", \"month\", \"day\")).map(\n",
    "        lambda ymd, mask_imgs: ic_date_groupby[ymd].mosaic().mask(mask_imgs.mosaic())\n",
    "    )\n",
    "\n",
    "def ndvi(ic: wf.ImageCollection) -> wf.ImageCollection:\n",
    "    nir, red = ic.unpack_bands(\"nir red\")\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    return ndvi.rename_bands(\"ndvi\")\n",
    "\n",
    "def isin(ic: wf.ImageCollection, values: list) -> wf.ImageCollection:\n",
    "    \"Like np.isin, for Workflows\"\n",
    "    assert len(values) > 0\n",
    "    result = False\n",
    "    for value in values:\n",
    "        result = result | (ic == value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```X_fp = r'/mnt/u_net_3d/saved_models/saved_data/x_rf.npy'\n",
    "y_fp = r'/mnt/u_net_3d/saved_models/saved_data/y_rf.npy'\n",
    "X_t = np.load(X_fp)\n",
    "y_t = np.load(y_fp)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grains_oils_grass_beans = [1,2,3,4,5,6,10,11,12,13,21,22,23,24,25,26,27,28,29,\n",
    "                        30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,51,\n",
    "                        52,53,225,226,228,230,232,234,235,236,237,238,239,240,241,254]\n",
    "\n",
    "deli_crops = [14, 48, 49, 50, 54, 55, 57, 206, 207, 208, 209, 213, 214, 216,\n",
    "            219, 221, 222, 224, 227, 229, 231, 242, 243, 244, 245, 246, 247,\n",
    "            248, 249, 250]\n",
    "\n",
    "tree_crops = [66, 67, 68, 69, 72, 74, 75, 76, 77, 204, 210, 211, 212, 215, 217,\n",
    "            218,220, 223]\n",
    "\n",
    "crops_list = deli_crops + tree_crops\n",
    "crops_enc = {id_: k + 1 for k, id_ in enumerate(sorted(crops_list))}\n",
    "crops_enc[0] = 0\n",
    "crops_dec = {crops_enc[id_]: id_ for id_ in crops_enc}\n",
    "def process_crop_split(x):\n",
    "    split = x.split()\n",
    "    crop = ''\n",
    "    for s in split:\n",
    "        if not s.isnumeric():\n",
    "            crop += f\"{s} \"\n",
    "        else:\n",
    "            return crop[:-1], int(s)\n",
    "# replace ... with full path on your machine\n",
    "fp = r'/mnt/u_net_3d/saved_models/saved_data/label_map.txt'\n",
    "text = \"\"\n",
    "with open(fp, 'r') as file:\n",
    "    for line in file.read():\n",
    "        text += line\n",
    "text = text.split('\\n')[3:]\n",
    "crop_label_enc = {process_crop_split(x)[1]: process_crop_split(x)[0] for x in text}\n",
    "crop_label_dec = {crop_label_enc[k]: k for k in crop_label_enc}\n",
    "#y_t = np.array([crop_label_enc[crops_dec[y_]] for y_ in y_t])\n",
    "#X_l = X_t.reshape(X_t.shape[0], 12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_l = np.zeros((y_t.shape[0], 78))\\nfor k, y in enumerate(y_t):\\n    y_l[k][crop_one_hot[y]] = 1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_one_hot = {crop: k for k, crop in enumerate(sorted(list(crop_label_dec)))}\n",
    "crop_one_hot_dec = {crop_one_hot[c]: c for c in crop_one_hot}\n",
    "'''y_l = np.zeros((y_t.shape[0], 78))\n",
    "for k, y in enumerate(y_t):\n",
    "    y_l[k][crop_one_hot[y]] = 1'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_l, y_l, test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodNotImplemented",
     "evalue": "501 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMethodNotImplemented\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-dce43f749d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0ml8_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml8_with_ndvi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcdl_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mcentral_valley_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAOI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentral_valley_aoi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"EPSG:4326\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mall_cdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfour_year_binary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentral_valley_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mall_cdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsgpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpackb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_cdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsgpack_numpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mall_cdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geocontext'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gdal_geotrans\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/descarteslabs/workflows/__init__.py\u001b[0m in \u001b[0;36m_compute_mixin\u001b[0;34m(self, geoctx, format, destination, file, timeout, block, progress_bar, client, cache, **params)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/descarteslabs/workflows/__init__.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(obj, geoctx, format, destination, file, timeout, block, progress_bar, client, cache, **params)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m     )\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/descarteslabs/workflows/models/toplevel.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(obj, geoctx, format, destination, file, timeout, block, progress_bar, client, cache, **params)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     job = Job(\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/descarteslabs/workflows/models/job.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, proxy_object, parameters, format, destination, client, cache)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__channel__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             ),\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         )\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/descarteslabs/workflows/client/client.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             e._exceptions = [\n",
      "\u001b[0;31mMethodNotImplemented\u001b[0m: 501 "
     ]
    }
   ],
   "source": [
    "start_datetime = \"2019-01-01\"\n",
    "end_datetime = \"2020-01-01\"\n",
    "\n",
    "l8_daily = cloud_masked_daily_product(\n",
    "    \"landsat:LC08:01:T1:TOAR\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "\n",
    "s2_daily = cloud_masked_daily_product(\n",
    "    \"sentinel-2:L1C\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "\n",
    "l8_with_ndvi = l8_daily.concat_bands(ndvi(l8_daily))\n",
    "ab_ic = wf.ImageCollection.from_id(\n",
    "    \"airbus:oneatlas:spot:v2\", start_datetime=start_datetime, end_datetime=end_datetime\n",
    ").pick_bands(\"red green blue\")\n",
    "ab_date_groupby = ab_ic.groupby(dates=(\"year\", \"month\", \"day\"))\n",
    "ab_daily = ab_ic.groupby(dates=(\"year\", \"month\", \"day\")).map(\n",
    "        lambda ymd, mask_imgs: ab_date_groupby[ymd].mosaic())\n",
    "cdl = wf.ImageCollection.from_id(\n",
    "    \"usda:cdl:v1\", start_datetime=\"2016-01-01\", end_datetime=\"2019-01-01\"\n",
    ").pick_bands(\"class\")\n",
    "cdl_train = wf.ImageCollection.from_id(\n",
    "    \"usda:cdl:v1\", start_datetime=start_datetime, end_datetime=end_datetime\n",
    ").pick_bands(\"class\")\n",
    "\n",
    "\n",
    "grains_oils_grass_beans = [1,2,3,4,5,6,10,11,12,13,21,22,23,24,25,26,27,28,29,\n",
    "                        30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,51,\n",
    "                        52,53,225,226,228,230,232,234,235,236,237,238,239,240,241,254]\n",
    "\n",
    "deli_crops = [14, 48, 49, 50, 54, 55, 57, 206, 207, 208, 209, 213, 214, 216,\n",
    "            219, 221, 222, 224, 227, 229, 231, 242, 243, 244, 245, 246, 247,\n",
    "            248, 249, 250]\n",
    "\n",
    "tree_crops = [66, 67, 68, 69, 72, 74, 75, 76, 77, 204, 210, 211, 212, 215, 217,\n",
    "            218,220, 223]\n",
    "\n",
    "crops_list = deli_crops + tree_crops\n",
    "crops_enc = {id_: k + 1 for k, id_ in enumerate(sorted(crops_list))}\n",
    "crops_enc[0] = 0\n",
    "crops_dec = {crops_enc[id_]: id_ for id_ in crops_enc}\n",
    "\n",
    "is_crops = isin(cdl, crops_list)\n",
    "is_crops_19 = is_crops[-1]\n",
    "\n",
    "four_year_combo = is_crops.sum(axis=\"images\") + is_crops_19  # double-weight 2019\n",
    "four_year_binary = four_year_combo >= 2\n",
    "cdl_mask = ~four_year_binary\n",
    "l8_masked = l8_with_ndvi.mask(cdl_mask)\n",
    "central_valley_ctx = dl.scenes.AOI(central_valley_aoi, shape=(2048, 2048), crs=\"EPSG:4326\")\n",
    "all_cdl = four_year_binary.compute(central_valley_ctx)\n",
    "all_cdl = msgpack.unpackb(all_cdl, object_hook=msgpack_numpy.decode)\n",
    "all_cdl['geocontext'][\"gdal_geotrans\"]\n",
    "shapes = list(\n",
    "    geom for geom, value in\n",
    "    rasterio.features.shapes(\n",
    "        all_cdl['ndarray'].astype(\"uint8\"), \n",
    "        transform=rasterio.transform.Affine.from_gdal(*all_cdl['geocontext'][\"gdal_geotrans\"])\n",
    "    )\n",
    "    if value == 1\n",
    ")\n",
    "print(f\"length of shapes: {len(shapes)}\")\n",
    "all_valid = shapely.ops.unary_union([shapely.geometry.shape(s) for s in shapes]).simplify(0.3)\n",
    "print(f'Type of all_valid: {type(all_valid)}')\n",
    "all_valid_prepped = shapely.prepared.prep(all_valid)\n",
    "valid_tiles = [t for t in tqdm(tiles) if all_valid_prepped.intersects(t.geometry)]\n",
    "print(f'No. Valid Tiles: {len(valid_tiles)}')\n",
    "print(f'Percentage of valid tiles: {100*(len(valid_tiles) / len(tiles))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed\n",
    "from keras.layers import Dropout, Bidirectional, Concatenate\n",
    "from keras.layers import BatchNormalization, Conv1D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input((365, 5))\n",
    "conv = BatchNormalization()(input_)\n",
    "conv = Conv1D(128, 3, padding='same')(conv)\n",
    "conv = BatchNormalization()(conv)\n",
    "conv = Conv1D(128, 3, padding='same')(conv)\n",
    "conv = Conv1D(128, 3, padding='same')(conv)\n",
    "conv = BatchNormalization()(conv)\n",
    "conv = Conv1D(128, 3, padding='same')(conv)\n",
    "lst = BatchNormalization()(conv)\n",
    "lst = Bidirectional(LSTM(units=365, recurrent_dropout=0))(lst)\n",
    "out = Dropout(0.25)(lst)\n",
    "out = BatchNormalization()(out)\n",
    "out = Dense(78, activation='softmax')(out)\n",
    "model = Model(input_, out)\n",
    "sgd = keras.optimizers.Adam(lr=0.000007, clipvalue=50)\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_tile(tile, imagery):\n",
    "    if imagery == 'landsat':\n",
    "        l8_d = wf.compute([l8_daily.ndarray], #l8_daily.properties, cdl.ndarray], \n",
    "                          tile, format=\"msgpack\", progress_bar=False)\n",
    "        l8_inf = wf.compute([l8_daily.properties], \n",
    "                          tile, progress_bar=False)\n",
    "        cdl_d = wf.compute([cdl_train.ndarray], \n",
    "                          tile, format='msgpack', progress_bar=False)\n",
    "        l8_d = msgpack_to_numpy(l8_d)\n",
    "        cdl_d = msgpack_to_numpy(cdl_d)\n",
    "        img_t = get_yday_arrays(l8_d, l8_inf[0])\n",
    "    elif imagery == 'sentinel2':\n",
    "        s2_d = wf.compute([s2_daily.ndarray], #l8_daily.properties, cdl.ndarray], \n",
    "                          tile, format=\"msgpack\", progress_bar=False)\n",
    "        s2_inf = wf.compute([s2_daily.properties], \n",
    "                          tile, progress_bar=False)\n",
    "        cdl_d = wf.compute([cdl_train.ndarray], \n",
    "                          tile, format='msgpack', progress_bar=False)\n",
    "        s2_d = msgpack_to_numpy(s2_d)\n",
    "        cdl_d = msgpack_to_numpy(cdl_d)\n",
    "        img_t = get_yday_arrays(s2_d, s2_inf[0])\n",
    "    Xtt, ytt = get_dnn_data(img_t, cdl_d, crops_list)\n",
    "    ytt = np.array([crop_label_enc[crops_dec[y_]] for y_ in ytt])\n",
    "    y_res = np.zeros((ytt.shape[0], 78))\n",
    "    for k, y in enumerate(ytt):\n",
    "        y_res[k][crop_one_hot[y]] = 1\n",
    "    return Xtt, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, tile in enumerate(valid_tiles):\n",
    "    try:\n",
    "        print(f\"Tile {k+1} out of 67\")\n",
    "        X_tt, y_tt = get_train_tile(tile, 'sentinel2')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_tt, y_tt, test_size=0.10, random_state=2020)\n",
    "        #model.fit(X_train, y_train, batch_size=256, epochs=1, validation_data=[X_test, y_test])\n",
    "        #K.set_value(model.optimizer.learning_rate, 0.00009)\n",
    "        model.fit(X_train, y_train, batch_size=min(256, X_tt.shape[0]),\n",
    "                  epochs=3, validation_data=[X_test, y_test])\n",
    "        #K.set_value(model.optimizer.learning_rate, 0.0001)\n",
    "        #X_ttt = np.concatenate((X_train, X_tt))\n",
    "        #y_ttt = np.concatenate((y_train, y_tt))\n",
    "        #shuff = np.arange(X_ttt.shape[0])\n",
    "        #np.random.shuffle(shuff)\n",
    "        #K.set_value(model.optimizer.learning_rate, 0.00009)\n",
    "        model.fit(X_tt, y_tt, batch_size=256, epochs=2, validation_data=[X_test, y_test])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'/mnt/u_net_3d/saved_models/model365_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = \"2018-01-01\"\n",
    "end_datetime = \"2019-01-01\"\n",
    "l8_daily = cloud_masked_daily_product(\n",
    "    \"landsat:LC08:01:T1:TOAR\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "s2_daily = cloud_masked_daily_product(\n",
    "    \"sentinel-2:L1C\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "y18_true, y18_pred = [], []\n",
    "for k, tile in enumerate(valid_tiles):\n",
    "    try:\n",
    "        X_tt, y_tt = get_train_tile(tile, 'sentinel2')\n",
    "        cur_pred = model.predict(X_tt).argmax(-1)\n",
    "        y18_pred += cur_pred.tolist()\n",
    "        y18_true += y_tt.argmax(-1).tolist()\n",
    "        print(f\"Iteration {k+1} / 67 accuracy: {accuracy_score(y_tt.argmax(-1), cur_pred)}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y18_true, y18_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, batch_size=64, epochs=15, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "def get_conf_matrix(y_true, y_pred, labels, save=False):\n",
    "    df = pd.DataFrame(confusion_matrix(y_true, y_pred, labels))\n",
    "    df.columns = [f'Predicted {lab}' for lab in labels]\n",
    "    df.index = [f'True {lab}' for lab in labels]\n",
    "    cmap = sns.light_palette((237, 85, 74), input=\"husl\",as_cmap=True)\n",
    "    plt.figure(figsize=(30,30))\n",
    "    sns.heatmap(df,annot=True, fmt='d', cbar=0, cmap=cmap, annot_kws={\"size\": 20})\n",
    "    if save:\n",
    "        plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [crop_one_hot_dec[y] for y in model.predict(X_test).argmax(-1)]\n",
    "y_true = [crop_one_hot_dec[y] for y in y_test.argmax(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_true, preds))\n",
    "get_conf_matrix(y_true, preds, [crop for crop in list(crop_one_hot) if crop in y_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_datetime = \"2018-01-01\"\n",
    "end_datetime = \"2019-01-01\"\n",
    "l8_daily = cloud_masked_daily_product(\n",
    "    \"landsat:LC08:01:T1:TOAR\", start_datetime, end_datetime\n",
    ").pick_bands(\"red green blue nir swir1\")\n",
    "l8_with_ndvi = l8_daily.concat_bands(ndvi(l8_daily))\n",
    "ab_ic = wf.ImageCollection.from_id(\n",
    "    \"airbus:oneatlas:spot:v2\", start_datetime=start_datetime, end_datetime=end_datetime\n",
    ").pick_bands(\"red green blue\")\n",
    "ab_date_groupby = ab_ic.groupby(dates=(\"year\", \"month\", \"day\"))\n",
    "ab_daily = ab_ic.groupby(dates=(\"year\", \"month\", \"day\")).map(\n",
    "        lambda ymd, mask_imgs: ab_date_groupby[ymd].mosaic())\n",
    "cdl = wf.ImageCollection.from_id(\n",
    "    \"usda:cdl:v1\", start_datetime=\"2018-01-01\", end_datetime=\"2019-01-01\"\n",
    ").pick_bands(\"class\")\n",
    "\n",
    "grains_oils_grass_beans = [1,2,3,4,5,6,10,11,12,13,21,22,23,24,25,26,27,28,29,\n",
    "                        30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,51,\n",
    "                        52,53,225,226,228,230,232,234,235,236,237,238,239,240,241,254]\n",
    "\n",
    "deli_crops = [14, 48, 49, 50, 54, 55, 57, 206, 207, 208, 209, 213, 214, 216,\n",
    "            219, 221, 222, 224, 227, 229, 231, 242, 243, 244, 245, 246, 247,\n",
    "            248, 249, 250]\n",
    "\n",
    "tree_crops = [66, 67, 68, 69, 72, 74, 75, 76, 77, 204, 210, 211, 212, 215, 217,\n",
    "            218,220, 223]\n",
    "\n",
    "crops_list = deli_crops + tree_crops\n",
    "crops_enc = {id_: k + 1 for k, id_ in enumerate(sorted(crops_list))}\n",
    "crops_enc[0] = 0\n",
    "crops_dec = {crops_enc[id_]: id_ for id_ in crops_enc}\n",
    "\n",
    "is_crops = isin(cdl, crops_list)\n",
    "is_crops_19 = is_crops[-1]\n",
    "\n",
    "four_year_combo = is_crops.sum(axis=\"images\") + is_crops_19  # double-weight 2019\n",
    "four_year_binary = four_year_combo >= 2\n",
    "cdl_mask = ~four_year_binary\n",
    "\n",
    "l8_masked = l8_with_ndvi.mask(cdl_mask)\n",
    "central_valley_ctx = dl.scenes.AOI(central_valley_aoi, shape=(2048, 2048), crs=\"EPSG:4326\")\n",
    "all_cdl = four_year_binary.compute(central_valley_ctx, format='msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0][0, :3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.transpose(test[0].mean(0)[:3], (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_labels, create_pairwise_bilateral, create_pairwise_gaussian\n",
    "import cv2\n",
    "from skimage.color import gray2rgb\n",
    "from skimage.color import rgb2gray\n",
    "#Original_image = Image which has to labelled\n",
    "#Annotated image = Which has been labelled by some technique( FCN in this case)\n",
    "#Output_image = Name of the final output image after applying CRF\n",
    "#Use_2d = boolean variable \n",
    "#if use_2d = True specialised 2D fucntions will be applied\n",
    "#else Generic functions will be applied\n",
    "\n",
    "def crf(original_image, annotated_image,output_image, use_2d = True):\n",
    "    \n",
    "    # Converting annotated image to RGB if it is Gray scale\n",
    "    if(len(annotated_image.shape)<3):\n",
    "        annotated_image = gray2rgb(annotated_image).astype(np.uint32)\n",
    "    \n",
    "    #cv2.imwrite(\"testing2.png\",annotated_image)\n",
    "    annotated_image = annotated_image.astype(np.uint32)\n",
    "    #Converting the annotations RGB color to single 32 bit integer\n",
    "    annotated_label = annotated_image[:,:,0].astype(np.uint32) + (annotated_image[:,:,1]<<8).astype(np.uint32) + (annotated_image[:,:,2]<<16).astype(np.uint32)\n",
    "    \n",
    "    # Convert the 32bit integer color to 0,1, 2, ... labels.\n",
    "    colors, labels = np.unique(annotated_label, return_inverse=True)\n",
    "    \n",
    "    #Creating a mapping back to 32 bit colors\n",
    "    colorize = np.empty((len(colors), 3), np.uint8)\n",
    "    colorize[:,0] = (colors & 0x0000FF)\n",
    "    colorize[:,1] = (colors & 0x00FF00) >> 8\n",
    "    colorize[:,2] = (colors & 0xFF0000) >> 16\n",
    "    \n",
    "    #Gives no of class labels in the annotated image\n",
    "    n_labels = len(set(labels.flat)) \n",
    "    \n",
    "    print(\"No of labels in the Image are \")\n",
    "    print(n_labels)\n",
    "    \n",
    "    \n",
    "    #Setting up the CRF model\n",
    "    if use_2d :\n",
    "        d = dcrf.DenseCRF2D(original_image.shape[1], original_image.shape[0], n_labels)\n",
    "\n",
    "        # get unary potentials (neg log probability)\n",
    "        U = unary_from_labels(labels, n_labels, gt_prob=0.55, zero_unsure=False)\n",
    "        d.setUnaryEnergy(U)\n",
    "\n",
    "        # This adds the color-independent term, features are the locations only.\n",
    "        d.addPairwiseGaussian(sxy=(5, 5), compat=5,\n",
    "                              kernel=dcrf.FULL_KERNEL,\n",
    "                          normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "\n",
    "        # This adds the color-dependent term, i.e. features are (x,y,r,g,b).\n",
    "        d.addPairwiseBilateral(sxy=(40, 40), srgb=(5, 5, 5), rgbim=original_image,\n",
    "                           compat=25,\n",
    "                           kernel=dcrf.FULL_KERNEL,\n",
    "                           normalization=dcrf.NORMALIZE_SYMMETRIC)\n",
    "        \n",
    "    #Run Inference for 5 steps \n",
    "    Q = d.inference(5)\n",
    "\n",
    "    # Find out the most probable class for each pixel.\n",
    "    MAP = np.argmax(Q, axis=0)\n",
    "\n",
    "    # Convert the MAP (labels) back to the corresponding colors and save the image.\n",
    "    # Note that there is no \"unknown\" here anymore, no matter what we had at first.\n",
    "    MAP = colorize[MAP,:]\n",
    "    cv2.imwrite(output_image,MAP.reshape(original_image.shape))\n",
    "    return MAP.reshape(original_image.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
